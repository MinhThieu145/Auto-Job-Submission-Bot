{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import openai    \n",
    "openai.api_key=''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cloud solutions intern.csv', 'business analyst intern.csv', 'cloud engineer intern.csv', 'cloud infrastructure architect intern.csv', 'cloud architect intern.csv', 'data analyst intern.csv', 'devops engineer intern.csv', 'devops architect intern.csv', 'cloud systems architect intern.csv', 'data intern.csv', 'data scientist intern.csv']\n",
      "['cloud solutions intern.csv', 'business analyst intern.csv', 'cloud engineer intern.csv', 'cloud infrastructure architect intern.csv', 'cloud architect intern.csv', 'data analyst intern.csv', 'devops engineer intern.csv', 'devops architect intern.csv', 'quantitative analyst intern.csv', 'cloud systems architect intern.csv', 'devops specialist intern.csv', 'data intern.csv', 'data scientist intern.csv', 'data engineer intern.csv']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# list all folder in scrapers\n",
    "scraper_list = os.listdir('scrapers')\n",
    "\n",
    "# loop over those folder\n",
    "for scraper in scraper_list:\n",
    "    # go inside a folder called result\n",
    "    result_folder_path = 'scrapers/' + scraper + '/result'\n",
    "\n",
    "    # list all the files inside result folder\n",
    "    result_files = os.listdir(result_folder_path)\n",
    "    print(result_files)\n",
    "\n",
    "    # loop over those files\n",
    "    for file in result_files:\n",
    "        # get the file name \n",
    "        file_name = file.split('.')[0]\n",
    "        print('file name: ', file_name)\n",
    "\n",
    "        # get the 3 columns from the file: job_title, job_link and description and create a dataframe from them\n",
    "        file_data = pd.read_csv(result_folder_path + '/' + file)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list folder\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "os.listdir('./scrapers/linkedin-scraper/result/')\n",
    "\n",
    "# get a file in result folder\n",
    "df = pd.read_csv('./scrapers/linkedin-scraper/result/data scientist intern.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>job_link</th>\n",
       "      <th>description</th>\n",
       "      <th>company_name</th>\n",
       "      <th>company_link</th>\n",
       "      <th>job_location</th>\n",
       "      <th>workplace_type</th>\n",
       "      <th>post_date</th>\n",
       "      <th>number_of_applicants</th>\n",
       "      <th>skill_list</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>QA Engineer Intern</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/3637610060/...</td>\n",
       "      <td>About the job\\n\\n\\n\\n\\nPassionate people. Loya...</td>\n",
       "      <td>SAS</td>\n",
       "      <td>https://www.linkedin.com/company/sas/life/</td>\n",
       "      <td>Bloomington, MN</td>\n",
       "      <td>On-site</td>\n",
       "      <td>6 hours ago</td>\n",
       "      <td>12 applicants</td>\n",
       "      <td>[]</td>\n",
       "      <td>data scientist intern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Software Engineering Co-op (Fall 2023)</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/3641126197/...</td>\n",
       "      <td>About the job\\nJoin a team recognized for lead...</td>\n",
       "      <td>Honeywell</td>\n",
       "      <td>https://www.linkedin.com/company/honeywell/life/</td>\n",
       "      <td>Alpharetta, GA</td>\n",
       "      <td>On-site</td>\n",
       "      <td>2 hours ago</td>\n",
       "      <td>30 applicants</td>\n",
       "      <td>[]</td>\n",
       "      <td>data scientist intern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Software Engineering Co-op (Fall 2023)</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/3641126196/...</td>\n",
       "      <td>About the job\\nJoin a team recognized for lead...</td>\n",
       "      <td>Honeywell</td>\n",
       "      <td>https://www.linkedin.com/company/honeywell/life/</td>\n",
       "      <td>Mason, OH</td>\n",
       "      <td>On-site</td>\n",
       "      <td>2 hours ago</td>\n",
       "      <td>25 applicants</td>\n",
       "      <td>[]</td>\n",
       "      <td>data scientist intern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Undergraduate (Year-Round) Intern - PV Perform...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/3641403578/...</td>\n",
       "      <td>About the job\\nPosting Title\\n\\nUndergraduate ...</td>\n",
       "      <td>National Renewable Energy Laboratory</td>\n",
       "      <td>https://www.linkedin.com/company/national-rene...</td>\n",
       "      <td>Golden, CO</td>\n",
       "      <td>On-site</td>\n",
       "      <td>17 hours ago</td>\n",
       "      <td>4 applicants</td>\n",
       "      <td>[]</td>\n",
       "      <td>data scientist intern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023 Intern - Research Scientist/Engineer</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/3641149301/...</td>\n",
       "      <td>About the job\\nOur Company\\n\\nChanging the wor...</td>\n",
       "      <td>Adobe</td>\n",
       "      <td>https://www.linkedin.com/company/adobe/life/</td>\n",
       "      <td>San Jose, CA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50 minutes ago</td>\n",
       "      <td>14 applicants</td>\n",
       "      <td>[]</td>\n",
       "      <td>data scientist intern</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           job_title  \\\n",
       "0                                 QA Engineer Intern   \n",
       "1             Software Engineering Co-op (Fall 2023)   \n",
       "2             Software Engineering Co-op (Fall 2023)   \n",
       "3  Undergraduate (Year-Round) Intern - PV Perform...   \n",
       "4          2023 Intern - Research Scientist/Engineer   \n",
       "\n",
       "                                            job_link  \\\n",
       "0  https://www.linkedin.com/jobs/view/3637610060/...   \n",
       "1  https://www.linkedin.com/jobs/view/3641126197/...   \n",
       "2  https://www.linkedin.com/jobs/view/3641126196/...   \n",
       "3  https://www.linkedin.com/jobs/view/3641403578/...   \n",
       "4  https://www.linkedin.com/jobs/view/3641149301/...   \n",
       "\n",
       "                                         description  \\\n",
       "0  About the job\\n\\n\\n\\n\\nPassionate people. Loya...   \n",
       "1  About the job\\nJoin a team recognized for lead...   \n",
       "2  About the job\\nJoin a team recognized for lead...   \n",
       "3  About the job\\nPosting Title\\n\\nUndergraduate ...   \n",
       "4  About the job\\nOur Company\\n\\nChanging the wor...   \n",
       "\n",
       "                           company_name  \\\n",
       "0                                   SAS   \n",
       "1                             Honeywell   \n",
       "2                             Honeywell   \n",
       "3  National Renewable Energy Laboratory   \n",
       "4                                 Adobe   \n",
       "\n",
       "                                        company_link     job_location  \\\n",
       "0         https://www.linkedin.com/company/sas/life/  Bloomington, MN   \n",
       "1   https://www.linkedin.com/company/honeywell/life/   Alpharetta, GA   \n",
       "2   https://www.linkedin.com/company/honeywell/life/        Mason, OH   \n",
       "3  https://www.linkedin.com/company/national-rene...       Golden, CO   \n",
       "4       https://www.linkedin.com/company/adobe/life/     San Jose, CA   \n",
       "\n",
       "  workplace_type       post_date number_of_applicants skill_list  \\\n",
       "0        On-site     6 hours ago        12 applicants         []   \n",
       "1        On-site     2 hours ago        30 applicants         []   \n",
       "2        On-site     2 hours ago        25 applicants         []   \n",
       "3        On-site    17 hours ago         4 applicants         []   \n",
       "4            NaN  50 minutes ago        14 applicants         []   \n",
       "\n",
       "                   title  \n",
       "0  data scientist intern  \n",
       "1  data scientist intern  \n",
       "2  data scientist intern  \n",
       "3  data scientist intern  \n",
       "4  data scientist intern  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(prompt, model=\"gpt-3.5-turbo-0613\", temperature=0.0):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature, # this is the degree of randomness of the model's output\n",
    "    )\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = get_completion(\n",
    "    prompt=\"give me the name of 10 animals\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject at 0x7fe41f7da8e0> JSON: {\n",
       "  \"completion_tokens\": 45,\n",
       "  \"prompt_tokens\": 15,\n",
       "  \"total_tokens\": 60\n",
       "}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['usage']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetSummaryPrompt(job_description):\n",
    "\n",
    "    prompt = f'''\n",
    "    Your task is to generate a short summary of the job description to suggest key \\ \n",
    "    ideas to a job seeker. \\\n",
    "\n",
    "    Summarize the following job description, delimited by tripple bacticks: \\\n",
    "    in at most 3 sentences, and focus on key skills and requirements. \\\n",
    "\n",
    "    Job Description: ```{job_description}```\n",
    "\n",
    "    '''\n",
    "\n",
    "    response = get_completion(prompt)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract key details from the job description\n",
    "def GetKeyDetails(job_description):\n",
    "\n",
    "    prompt = f'''\n",
    "    Your task is to extract key information from a job description. \n",
    "\n",
    "    The job description is delimited by tripple bacticks\\\n",
    "    Format your response as a JSON object with the following keys listed below. \\\n",
    "    The description of each key is delimited by double bactick, this information is only for you to understand\\\n",
    "    the content of each key. Don't include it in your response. \n",
    "    - \"Job Title:\" ``What is the job title?``\n",
    "    - \"Technical Skills:\" ``Skills like C++, Saleforce, AWS are considered technical skills``\n",
    "    - \"Other Responsibilities:\" ``Skills like Business Analytics, Giving data-driven decisions are considered soft skills``\n",
    "    - \"General Technical SKills:\" ``Grouping technical skills into a more general category, like \"Cloud Computing\"``\n",
    "    - \"Background Clearance:\" `Broad knowledge of enterprise business systems, but particularly CRM, BI and BPM.\n",
    "    `Does the job require a background clearance? Answer in Yes or No``\n",
    "    - \"Years of Experience:\" ``How many years of experience are required?``\n",
    "    - \"Is this intern or entry position\" ``Answer in Yes or No``\n",
    "\n",
    "    Job Description: ```{job_description}```\n",
    "\n",
    "    '''\n",
    "\n",
    "    key_details = get_completion(prompt)\n",
    "    return key_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some Constant\n",
    "SLEEP_TIME_OPEN_AI_EACH_ROW = 1\n",
    "SLEEP_TIME_WHEN_FAILED = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define your own error\n",
    "class OpenAIError(Exception):\n",
    "    # define an error called ServiceUnavailableError\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AnalyzeDescription(df):\n",
    "\n",
    "    # get the number of rows\n",
    "    num_rows = df.shape[0]\n",
    "\n",
    "    i = 0\n",
    "    # loop over each row\n",
    "    while i < num_rows:\n",
    "        try:\n",
    "            # get the job description\n",
    "            job_description = df.iloc[i]['description']\n",
    "\n",
    "            # get the job summary\n",
    "            job_summary = GetSummaryPrompt(job_description)\n",
    "\n",
    "            # get the key details from the job description\n",
    "            key_details = GetKeyDetails(job_description)\n",
    "\n",
    "            # add the job summary and key details to the dataframe\n",
    "            df.loc[i, 'job_summary'] = job_summary\n",
    "            df.loc[i, 'key_details'] = key_details\n",
    "\n",
    "            # increment i\n",
    "            i += 1\n",
    "\n",
    "            # sleep for 1 second\n",
    "\n",
    "        except IndexError as e:\n",
    "            print(e)\n",
    "            print('failed at row: ', i)\n",
    "            time.sleep(SLEEP_TIME_WHEN_FAILED)\n",
    "            continue\n",
    "\n",
    "        except Exception as e:\n",
    "            # this is general error\n",
    "            print('This is a general error: ', e)\n",
    "            # no need to go on at this point\n",
    "            break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[54], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m new_df \u001b[39m=\u001b[39m AnalyzeDescription(df)\n\u001b[1;32m      3\u001b[0m new_df\n",
      "Cell \u001b[0;32mIn[53], line 14\u001b[0m, in \u001b[0;36mAnalyzeDescription\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     11\u001b[0m job_description \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39miloc[i][\u001b[39m'\u001b[39m\u001b[39mdescription\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     13\u001b[0m \u001b[39m# get the job summary\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m job_summary \u001b[39m=\u001b[39m GetSummaryPrompt(job_description)\n\u001b[1;32m     16\u001b[0m \u001b[39m# get the key details from the job description\u001b[39;00m\n\u001b[1;32m     17\u001b[0m key_details \u001b[39m=\u001b[39m GetKeyDetails(job_description)\n",
      "Cell \u001b[0;32mIn[49], line 14\u001b[0m, in \u001b[0;36mGetSummaryPrompt\u001b[0;34m(job_description)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mGetSummaryPrompt\u001b[39m(job_description):\n\u001b[1;32m      3\u001b[0m     prompt \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'''\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[39m    Your task is to generate a short summary of the job description to suggest key \u001b[39m\u001b[39m\\\u001b[39m\u001b[39m \u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[39m    ideas to a job seeker. \u001b[39m\u001b[39m\\\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     11\u001b[0m \n\u001b[1;32m     12\u001b[0m \u001b[39m    \u001b[39m\u001b[39m'''\u001b[39m\n\u001b[0;32m---> 14\u001b[0m     response \u001b[39m=\u001b[39m get_completion(prompt)\n\u001b[1;32m     15\u001b[0m     \u001b[39mreturn\u001b[39;00m response\n",
      "Cell \u001b[0;32mIn[21], line 3\u001b[0m, in \u001b[0;36mget_completion\u001b[0;34m(prompt, model, temperature)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_completion\u001b[39m(prompt, model\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mgpt-3.5-turbo-0613\u001b[39m\u001b[39m\"\u001b[39m, temperature\u001b[39m=\u001b[39m\u001b[39m0.0\u001b[39m):\n\u001b[1;32m      2\u001b[0m     messages \u001b[39m=\u001b[39m [{\u001b[39m\"\u001b[39m\u001b[39mrole\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39muser\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcontent\u001b[39m\u001b[39m\"\u001b[39m: prompt}]\n\u001b[0;32m----> 3\u001b[0m     response \u001b[39m=\u001b[39m openai\u001b[39m.\u001b[39;49mChatCompletion\u001b[39m.\u001b[39;49mcreate(\n\u001b[1;32m      4\u001b[0m         model\u001b[39m=\u001b[39;49mmodel,\n\u001b[1;32m      5\u001b[0m         messages\u001b[39m=\u001b[39;49mmessages,\n\u001b[1;32m      6\u001b[0m         temperature\u001b[39m=\u001b[39;49mtemperature, \u001b[39m# this is the degree of randomness of the model's output\u001b[39;49;00m\n\u001b[1;32m      7\u001b[0m     )\n\u001b[1;32m      8\u001b[0m     \u001b[39mreturn\u001b[39;00m response\u001b[39m.\u001b[39mchoices[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mmessage[\u001b[39m\"\u001b[39m\u001b[39mcontent\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/DataAnalyst/lib/python3.10/site-packages/openai/api_resources/chat_completion.py:25\u001b[0m, in \u001b[0;36mChatCompletion.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     26\u001b[0m     \u001b[39mexcept\u001b[39;00m TryAgain \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     27\u001b[0m         \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m time\u001b[39m.\u001b[39mtime() \u001b[39m>\u001b[39m start \u001b[39m+\u001b[39m timeout:\n",
      "File \u001b[0;32m~/anaconda3/envs/DataAnalyst/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    128\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[1;32m    129\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[1;32m    137\u001b[0m ):\n\u001b[1;32m    138\u001b[0m     (\n\u001b[1;32m    139\u001b[0m         deployment_id,\n\u001b[1;32m    140\u001b[0m         engine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[1;32m    151\u001b[0m     )\n\u001b[0;32m--> 153\u001b[0m     response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\n\u001b[1;32m    154\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    155\u001b[0m         url,\n\u001b[1;32m    156\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    157\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    158\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    159\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[1;32m    160\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[1;32m    161\u001b[0m     )\n\u001b[1;32m    163\u001b[0m     \u001b[39mif\u001b[39;00m stream:\n\u001b[1;32m    164\u001b[0m         \u001b[39m# must be an iterator\u001b[39;00m\n\u001b[1;32m    165\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[0;32m~/anaconda3/envs/DataAnalyst/lib/python3.10/site-packages/openai/api_requestor.py:220\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[1;32m    210\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    211\u001b[0m     method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    218\u001b[0m     request_timeout: Optional[Union[\u001b[39mfloat\u001b[39m, Tuple[\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    219\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[39mbool\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[0;32m--> 220\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrequest_raw(\n\u001b[1;32m    221\u001b[0m         method\u001b[39m.\u001b[39;49mlower(),\n\u001b[1;32m    222\u001b[0m         url,\n\u001b[1;32m    223\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    224\u001b[0m         supplied_headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    225\u001b[0m         files\u001b[39m=\u001b[39;49mfiles,\n\u001b[1;32m    226\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    227\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[1;32m    228\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[1;32m    229\u001b[0m     )\n\u001b[1;32m    230\u001b[0m     resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response(result, stream)\n\u001b[1;32m    231\u001b[0m     \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
      "File \u001b[0;32m~/anaconda3/envs/DataAnalyst/lib/python3.10/site-packages/openai/api_requestor.py:520\u001b[0m, in \u001b[0;36mAPIRequestor.request_raw\u001b[0;34m(self, method, url, params, supplied_headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    518\u001b[0m     _thread_context\u001b[39m.\u001b[39msession \u001b[39m=\u001b[39m _make_session()\n\u001b[1;32m    519\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 520\u001b[0m     result \u001b[39m=\u001b[39m _thread_context\u001b[39m.\u001b[39;49msession\u001b[39m.\u001b[39;49mrequest(\n\u001b[1;32m    521\u001b[0m         method,\n\u001b[1;32m    522\u001b[0m         abs_url,\n\u001b[1;32m    523\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    524\u001b[0m         data\u001b[39m=\u001b[39;49mdata,\n\u001b[1;32m    525\u001b[0m         files\u001b[39m=\u001b[39;49mfiles,\n\u001b[1;32m    526\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    527\u001b[0m         timeout\u001b[39m=\u001b[39;49mrequest_timeout \u001b[39mif\u001b[39;49;00m request_timeout \u001b[39melse\u001b[39;49;00m TIMEOUT_SECS,\n\u001b[1;32m    528\u001b[0m         proxies\u001b[39m=\u001b[39;49m_thread_context\u001b[39m.\u001b[39;49msession\u001b[39m.\u001b[39;49mproxies,\n\u001b[1;32m    529\u001b[0m     )\n\u001b[1;32m    530\u001b[0m \u001b[39mexcept\u001b[39;00m requests\u001b[39m.\u001b[39mexceptions\u001b[39m.\u001b[39mTimeout \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    531\u001b[0m     \u001b[39mraise\u001b[39;00m error\u001b[39m.\u001b[39mTimeout(\u001b[39m\"\u001b[39m\u001b[39mRequest timed out: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(e)) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/DataAnalyst/lib/python3.10/site-packages/requests/sessions.py:587\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    582\u001b[0m send_kwargs \u001b[39m=\u001b[39m {\n\u001b[1;32m    583\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m\"\u001b[39m: timeout,\n\u001b[1;32m    584\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    585\u001b[0m }\n\u001b[1;32m    586\u001b[0m send_kwargs\u001b[39m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 587\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(prep, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49msend_kwargs)\n\u001b[1;32m    589\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/anaconda3/envs/DataAnalyst/lib/python3.10/site-packages/requests/sessions.py:701\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    698\u001b[0m start \u001b[39m=\u001b[39m preferred_clock()\n\u001b[1;32m    700\u001b[0m \u001b[39m# Send the request\u001b[39;00m\n\u001b[0;32m--> 701\u001b[0m r \u001b[39m=\u001b[39m adapter\u001b[39m.\u001b[39;49msend(request, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    703\u001b[0m \u001b[39m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    704\u001b[0m elapsed \u001b[39m=\u001b[39m preferred_clock() \u001b[39m-\u001b[39m start\n",
      "File \u001b[0;32m~/anaconda3/envs/DataAnalyst/lib/python3.10/site-packages/requests/adapters.py:489\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    487\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    488\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m chunked:\n\u001b[0;32m--> 489\u001b[0m         resp \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49murlopen(\n\u001b[1;32m    490\u001b[0m             method\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mmethod,\n\u001b[1;32m    491\u001b[0m             url\u001b[39m=\u001b[39;49murl,\n\u001b[1;32m    492\u001b[0m             body\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mbody,\n\u001b[1;32m    493\u001b[0m             headers\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    494\u001b[0m             redirect\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    495\u001b[0m             assert_same_host\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    496\u001b[0m             preload_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    497\u001b[0m             decode_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    498\u001b[0m             retries\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_retries,\n\u001b[1;32m    499\u001b[0m             timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    500\u001b[0m         )\n\u001b[1;32m    502\u001b[0m     \u001b[39m# Send the request.\u001b[39;00m\n\u001b[1;32m    503\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    504\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(conn, \u001b[39m\"\u001b[39m\u001b[39mproxy_pool\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[0;32m~/anaconda3/envs/DataAnalyst/lib/python3.10/site-packages/urllib3/connectionpool.py:703\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    700\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_proxy(conn)\n\u001b[1;32m    702\u001b[0m \u001b[39m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m httplib_response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[1;32m    704\u001b[0m     conn,\n\u001b[1;32m    705\u001b[0m     method,\n\u001b[1;32m    706\u001b[0m     url,\n\u001b[1;32m    707\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout_obj,\n\u001b[1;32m    708\u001b[0m     body\u001b[39m=\u001b[39;49mbody,\n\u001b[1;32m    709\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    710\u001b[0m     chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    711\u001b[0m )\n\u001b[1;32m    713\u001b[0m \u001b[39m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[1;32m    714\u001b[0m \u001b[39m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[1;32m    715\u001b[0m \u001b[39m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[1;32m    716\u001b[0m \u001b[39m# mess.\u001b[39;00m\n\u001b[1;32m    717\u001b[0m response_conn \u001b[39m=\u001b[39m conn \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m release_conn \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/DataAnalyst/lib/python3.10/site-packages/urllib3/connectionpool.py:449\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    444\u001b[0m             httplib_response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39mgetresponse()\n\u001b[1;32m    445\u001b[0m         \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    446\u001b[0m             \u001b[39m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    447\u001b[0m             \u001b[39m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    448\u001b[0m             \u001b[39m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[0;32m--> 449\u001b[0m             six\u001b[39m.\u001b[39;49mraise_from(e, \u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    450\u001b[0m \u001b[39mexcept\u001b[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    451\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_raise_timeout(err\u001b[39m=\u001b[39me, url\u001b[39m=\u001b[39murl, timeout_value\u001b[39m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/DataAnalyst/lib/python3.10/site-packages/urllib3/connectionpool.py:444\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m    442\u001b[0m     \u001b[39m# Python 3\u001b[39;00m\n\u001b[1;32m    443\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 444\u001b[0m         httplib_response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49mgetresponse()\n\u001b[1;32m    445\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    446\u001b[0m         \u001b[39m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    447\u001b[0m         \u001b[39m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    448\u001b[0m         \u001b[39m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[1;32m    449\u001b[0m         six\u001b[39m.\u001b[39mraise_from(e, \u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/DataAnalyst/lib/python3.10/http/client.py:1375\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1373\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1374\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1375\u001b[0m         response\u001b[39m.\u001b[39;49mbegin()\n\u001b[1;32m   1376\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m:\n\u001b[1;32m   1377\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/anaconda3/envs/DataAnalyst/lib/python3.10/http/client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[39m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 318\u001b[0m     version, status, reason \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read_status()\n\u001b[1;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m status \u001b[39m!=\u001b[39m CONTINUE:\n\u001b[1;32m    320\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/DataAnalyst/lib/python3.10/http/client.py:279\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_read_status\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 279\u001b[0m     line \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfp\u001b[39m.\u001b[39;49mreadline(_MAXLINE \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m), \u001b[39m\"\u001b[39m\u001b[39miso-8859-1\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    280\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(line) \u001b[39m>\u001b[39m _MAXLINE:\n\u001b[1;32m    281\u001b[0m         \u001b[39mraise\u001b[39;00m LineTooLong(\u001b[39m\"\u001b[39m\u001b[39mstatus line\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/DataAnalyst/lib/python3.10/socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    704\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 705\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[1;32m    706\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[1;32m    707\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/DataAnalyst/lib/python3.10/ssl.py:1274\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1270\u001b[0m     \u001b[39mif\u001b[39;00m flags \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   1271\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1272\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[1;32m   1273\u001b[0m           \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m)\n\u001b[0;32m-> 1274\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(nbytes, buffer)\n\u001b[1;32m   1275\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1276\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m~/anaconda3/envs/DataAnalyst/lib/python3.10/ssl.py:1130\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1128\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1129\u001b[0m     \u001b[39mif\u001b[39;00m buffer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1130\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mread(\u001b[39mlen\u001b[39;49m, buffer)\n\u001b[1;32m   1131\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1132\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sslobj\u001b[39m.\u001b[39mread(\u001b[39mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "new_df = AnalyzeDescription(df)\n",
    "\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ServiceUnavailableError(Exception):\n",
    "    # say that openai is overloaded\n",
    "\n",
    "    def __init__(self, message=\"OpenAI is overloaded\"):\n",
    "        self.message = message\n",
    "        super().__init__(self.message)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed at row:  18\n",
      "failed at row:  19\n",
      "failed at row:  20\n",
      "failed at row:  21\n",
      "failed at row:  22\n",
      "failed at row:  23\n",
      "failed at row:  24\n",
      "failed at row:  25\n",
      "failed at row:  26\n",
      "failed at row:  27\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[65], line 3\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m----> 3\u001b[0m     random_job_description \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39;49miloc[i][\u001b[39m'\u001b[39m\u001b[39mdescription\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m      5\u001b[0m     GetSummaryPrompt(random_job_description)\n",
      "File \u001b[0;32m~/anaconda3/envs/DataAnalyst/lib/python3.10/site-packages/pandas/core/indexing.py:1073\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1072\u001b[0m maybe_callable \u001b[39m=\u001b[39m com\u001b[39m.\u001b[39mapply_if_callable(key, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj)\n\u001b[0;32m-> 1073\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_axis(maybe_callable, axis\u001b[39m=\u001b[39;49maxis)\n",
      "File \u001b[0;32m~/anaconda3/envs/DataAnalyst/lib/python3.10/site-packages/pandas/core/indexing.py:1625\u001b[0m, in \u001b[0;36m_iLocIndexer._getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1624\u001b[0m \u001b[39m# validate the location\u001b[39;00m\n\u001b[0;32m-> 1625\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_integer(key, axis)\n\u001b[1;32m   1627\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_ixs(key, axis\u001b[39m=\u001b[39maxis)\n",
      "File \u001b[0;32m~/anaconda3/envs/DataAnalyst/lib/python3.10/site-packages/pandas/core/indexing.py:1557\u001b[0m, in \u001b[0;36m_iLocIndexer._validate_integer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1556\u001b[0m \u001b[39mif\u001b[39;00m key \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m len_axis \u001b[39mor\u001b[39;00m key \u001b[39m<\u001b[39m \u001b[39m-\u001b[39mlen_axis:\n\u001b[0;32m-> 1557\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mIndexError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39msingle positional indexer is out-of-bounds\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mIndexError\u001b[0m: single positional indexer is out-of-bounds",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[65], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mIndexError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m      9\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mfailed at row: \u001b[39m\u001b[39m'\u001b[39m, i)\n\u001b[0;32m---> 10\u001b[0m     time\u001b[39m.\u001b[39;49msleep(SLEEP_TIME_WHEN_FAILED)\n\u001b[1;32m     12\u001b[0m \u001b[39mexcept\u001b[39;00m ServiceUnavailableError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     13\u001b[0m     \u001b[39mprint\u001b[39m(e)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    try:\n",
    "        random_job_description = df.iloc[i]['description']\n",
    "\n",
    "        GetSummaryPrompt(random_job_description)\n",
    "\n",
    "        GetKeyDetails(random_job_description)\n",
    "    except IndexError as e:\n",
    "        print('failed at row: ', i)\n",
    "        time.sleep(SLEEP_TIME_WHEN_FAILED)\n",
    "\n",
    "    except ServiceUnavailableError as e:\n",
    "        print(e)\n",
    "        print('failed at row: ', i)\n",
    "        print('open ai fucked up')\n",
    "        time.sleep(SLEEP_TIME_WHEN_FAILED)\n",
    "\n",
    "    except Exception as e:\n",
    "        # general error\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.to_csv('new_df.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Job Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "About the job\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Passionate people. Loyal clients. Leading solutions.\n",
      "\n",
      "With a rich culture of creative collaboration and professional growth, IDeaS’ team members build successful careers with us.\n",
      "\n",
      "IDeaS is proud to be a global powerhouse of innovation and excellence; challenge and reward. No matter where we’re working, our teams come together to create leading revenue management solutions that accelerate our clients’ growth through revenue optimization.\n",
      "\n",
      "Now we just need you!\n",
      "\n",
      "As a member of the IDeaS Software Development team our interns will participate in all aspects of the software development lifecycle. You will join an autonomous delivery team that is following agile methodologies in actively creating new features to enhance our revenue management products. While on our team, you will have a great opportunity to expand your technical skillset as well as work in an agile environment that believes in test-first, continuous integration and deployment. Your team’s code will be built and deployed to serve clients in over 140 countries.\n",
      "\n",
      "What you’ll be doing...\n",
      "\n",
      "This is NOT an intern project. You will work with team members around the world to design and test applications.\n",
      "Find innovative solutions to real problems for real clients\n",
      "You’ll be using some of the following technologies (depending on team placement):\n",
      "Cypress SQL Server\n",
      "MongoDB\n",
      "Datadog\n",
      "AWS\n",
      "API testing\n",
      "K6 - Performance\n",
      "RabbitMQ\n",
      "RestAssured\n",
      "MySQL Mobile testing tools IOS/Appium\n",
      "Selenium\n",
      "Analyze user stories/requirements, design test plan, create and execute test cases.\n",
      "Enhance continuous integration using Github and other in-house tools.\n",
      "Under the guidance of the Lead Engineer, design and develop test tools and test strategies.\n",
      "Resolve test failures due to, but not limited to, integration, cross feature impact.\n",
      "What you’ll bring to us…\n",
      "\n",
      "Planned degree in Computer Science or CE (undergraduate or graduate).\n",
      "Completed at least 3 years of undergraduate degree (by time of internship) in targeted program and/or have pervious related experience.\n",
      "Experience with different Test Frameworks/Automation Manual either via coursework or industry experience.\n",
      "Demonstration of using technical skills outside of classroom work including TA, RA, personal projects, or previous internships.\n",
      "We Support Who You Are….\n",
      "\n",
      "As a global company, we strive to create an inclusive environment where diverse perspectives spark innovation and meet the challenges of an evolving world. Whether you’re launching a new career or expanding your current one, IDeaS is a company where you can balance great work with all other aspects of your life.\n",
      "\n",
      "At IDeaS, we also aspire to live our values each day by being Accountable, Curious, Passionate and Authentic. And we continue our quest to build a more inclusive environment that attracts, represents and provides a place for diverse ideas, unique perspectives, and authentic voices.\n",
      "\n",
      "Additional Information:\n",
      "To qualify, applicants must be legally authorized to work in the United States, and should not require, now or in the future, sponsorship for employment visa status.\n",
      "\n",
      "SAS is an equal opportunity employer. All qualified applicants are considered for employment without regard to race, color, religion, gender, sexual orientation, gender identity, age, national origin, disability status, protected veteran status or any other characteristic protected by law. Read more: Equal Employment Opportunity is the Law. Also view the supplement EEO is the Law, and the notice Pay Transparency\n",
      "\n",
      "Equivalent combination of education, training, and relevant experience may be considered in place of the education requirement stated above.\n",
      "\n",
      "Resumes may be considered in the order they are received.\n",
      "\n",
      "IDeaS/SAS employees performing certain job functions may require access to technology or software subject to export or import regulations. To comply with these regulations, IDeaS/SAS may obtain nationality or citizenship information from applicants for employment. IDeaS/SAS collects this information solely for trade law compliance purposes and does not use it to discriminate unfairly in the hiring process.\n"
     ]
    }
   ],
   "source": [
    "print(job_description)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(prompt, model=\"gpt-3.5-turbo-0613\", temperature=0.0):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature, # this is the degree of randomness of the model's output\n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarize the job description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IDeaS is seeking interns to join their Software Development team and participate in all aspects of the software development lifecycle. Key skills and requirements include a planned degree in Computer Science or CE, completed at least 3 years of undergraduate degree, experience with different Test Frameworks/Automation Manual, and the ability to analyze user stories/requirements and design test plans. The company values diversity and strives to create an inclusive environment.\n"
     ]
    }
   ],
   "source": [
    "prompt = f'''\n",
    "Your task is to generate a short summary of the job description to suggest key \\ \n",
    "ideas to a job seeker. \\\n",
    "\n",
    "Summarize the following job description, delimited by tripple bacticks: \\\n",
    "in at most 3 sentences, and focus on key skills and requirements. \\\n",
    "\n",
    "Job Description: ```{job_description}```\n",
    "\n",
    "'''\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Job Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"Job Title\": \"Software Development Intern\",\n",
      "  \"Technical Skills\": [\n",
      "    \"Cypress\",\n",
      "    \"SQL Server\",\n",
      "    \"MongoDB\",\n",
      "    \"Datadog\",\n",
      "    \"AWS\",\n",
      "    \"API testing\",\n",
      "    \"K6 - Performance\",\n",
      "    \"RabbitMQ\",\n",
      "    \"RestAssured\",\n",
      "    \"MySQL\",\n",
      "    \"Mobile testing tools IOS/Appium\",\n",
      "    \"Selenium\"\n",
      "  ],\n",
      "  \"Other Responsibilities\": [\n",
      "    \"Analyze user stories/requirements, design test plan, create and execute test cases.\",\n",
      "    \"Enhance continuous integration using Github and other in-house tools.\",\n",
      "    \"Under the guidance of the Lead Engineer, design and develop test tools and test strategies.\",\n",
      "    \"Resolve test failures due to, but not limited to, integration, cross feature impact.\"\n",
      "  ],\n",
      "  \"General Technical Skills\": [\n",
      "    \"Software Development\",\n",
      "    \"Test Automation\",\n",
      "    \"Continuous Integration\"\n",
      "  ],\n",
      "  \"Background Clearance\": \"No\",\n",
      "  \"Years of Experience\": \"N/A (Internship position)\",\n",
      "  \"Is this intern or entry position\": \"Yes\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Extract key details from the job description\n",
    "\n",
    "prompt = f'''\n",
    "Your task is to extract key information from a job description. \n",
    "\n",
    "The job description is delimited by tripple bacticks\\\n",
    "Format your response as a JSON object with the following keys listed below. \\\n",
    "The description of each key is delimited by double bactick, this information is only for you to understand\\\n",
    "the content of each key. Don't include it in your response. \n",
    "- \"Job Title:\" ``What is the job title?``\n",
    "- \"Technical Skills:\" ``Skills like C++, Saleforce, AWS are considered technical skills``\n",
    "- \"Other Responsibilities:\" ``Skills like Business Analytics, Giving data-driven decisions are considered soft skills``\n",
    "- \"General Technical SKills:\" ``Grouping technical skills into a more general category, like \"Cloud Computing\"``\n",
    "- \"Background Clearance:\" `Broad knowledge of enterprise business systems, but particularly CRM, BI and BPM.\n",
    "`Does the job require a background clearance? Answer in Yes or No``\n",
    "- \"Years of Experience:\" ``How many years of experience are required?``\n",
    "- \"Is this intern or entry position\" ``Answer in Yes or No``\n",
    "\n",
    "Job Description: ```{job_description}```\n",
    "\n",
    "'''\n",
    "\n",
    "key_detail_job = get_completion(prompt)\n",
    "print(key_detail_job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/thieu/DataScience2/AutoJobSubmittion/run-everyday-stuff/scrapers\n"
     ]
    }
   ],
   "source": [
    "current_dir = os.getcwd()\n",
    "\n",
    "# find the scraper folder\n",
    "scraper_list = os.path.join(current_dir, 'scrapers')\n",
    "print(scraper_list)\n",
    "\n",
    "for scraper in os.listdir(scraper_list):\n",
    "    print(scraper)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataAnalyst",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
